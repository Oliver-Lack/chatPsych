# Example environment variables for chatPsych
# Copy this file to the base directory of the app as a a new file called .env and fill in your actual API keys below.

# Flask Configuration
FLASK_SECRET_KEY=your_secret_key_here

# Researcher Access
researcher_username=your_researcher_username
researcher_password=your_researcher_password

# ======================================
# PRIMARY LLM PROVIDERS
# ======================================

# OpenAI - Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your_openai_api_key_here

# Anthropic - Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key_here

# Google AI Studio - Get from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# XAI (Grok) - Get from: https://console.x.ai/
XAI_API_KEY=your_xai_api_key_here

# ======================================
# EXPANDED PROVIDER SUPPORT
# ======================================

# Groq - Very fast inference - Get from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Perplexity - Search-augmented AI - Get from: https://www.perplexity.ai/settings/api
PERPLEXITYAI_API_KEY=your_perplexity_api_key_here

# Mistral AI - European AI company - Get from: https://console.mistral.ai/
MISTRAL_API_KEY=your_mistral_api_key_here

# Cohere - Enterprise AI platform - Get from: https://dashboard.cohere.ai/api-keys
COHERE_API_KEY=your_cohere_api_key_here

# AI21 Labs - Jurassic models - Get from: https://studio.ai21.com/account/api-key
AI21_API_KEY=your_ai21_api_key_here

# ======================================
# CLOUD PROVIDER INTEGRATIONS
# ======================================

# Azure OpenAI - Get from Azure Portal
AZURE_API_KEY=your_azure_api_key_here
AZURE_API_BASE=https://your-resource.openai.azure.com/
AZURE_API_VERSION=2024-02-01

# AWS Bedrock - Configure via AWS CLI or environment
AWS_ACCESS_KEY_ID=your_aws_access_key_id
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
AWS_REGION_NAME=us-east-1

# ======================================
# FAST INFERENCE PLATFORMS
# ======================================

# Together AI - Open source models - Get from: https://api.together.xyz/settings/api-keys
TOGETHER_API_KEY=your_together_api_key_here

# Fireworks AI - Fast inference - Get from: https://fireworks.ai/account/api-keys
FIREWORKS_API_KEY=your_fireworks_api_key_here

# Replicate - Community models - Get from: https://replicate.com/account/api-tokens
REPLICATE_API_TOKEN=your_replicate_token_here

# DeepSeek - Chinese AI models - Get from: https://platform.deepseek.com/api_keys
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# ======================================
# SPECIALIZED PROVIDERS
# ======================================

# Cerebras - AI chip company - Get from: https://cloud.cerebras.ai/
CEREBRAS_API_KEY=your_cerebras_api_key_here

# NVIDIA NIM - NVIDIA inference - Get from: https://build.nvidia.com/
NVIDIA_NIM_API_KEY=your_nvidia_api_key_here

# OpenRouter - Multi-provider aggregator - Get from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Hugging Face - Transformers and Inference API - Get from: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your_huggingface_token_here

# ======================================
# LOCAL/SELF-HOSTED OPTIONS
# ======================================

# Ollama - Local model runner - Install: https://ollama.ai/
# No API key needed, just ensure Ollama is running locally
OLLAMA_API_BASE=http://localhost:11434


# ======================================
# NOTES
# ======================================
# 1. You don't need ALL of these keys - only set up the providers you want to use
# 2. Some providers (Ollama,) run locally and don't need API keys (You'll need some good hardware for this option lol)
# 3. Cloud providers (Azure, AWS) are for future features and require additional setup beyond API keys
